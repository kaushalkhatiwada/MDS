---
title: "2nd assessment exam"
author: "roll 10"
date: "2024-05-31"
output:
  pdf_document: default
  html_document: default
---


## QUESTION NO 7
```{r}

data <- airquality
str(data)

# Convert Month to a factor variable
data$Month <- as.factor(data$Month)

# Calculate the mean and standard deviation of Temp by Month
Temp_mean <- tapply(data$Temp, data$Month, mean, na.rm = TRUE)
Temp_sd <- tapply(data$Temp, data$Month, sd, na.rm = TRUE)

# Create a data frame to display the results
monthly_Temp_data <- data.frame(
  Month = names(Temp_mean),
  Mean_Temp = Temp_mean,
  SD_Temp = Temp_sd
)
monthly_Temp_data

#a) Perform goodness-of-fit test on Temp variable by Month variable to check if 
# it follows normal distribution or not



# Perform Shapiro-Wilk test for normality within each month
result <- tapply(data$Temp, data$Month, shapiro.test)
print(result)

## The data follows a normal distribution within each month as p value is greater than 0.05.

#b)	Perform goodness-of-fit test on Temp variable by Month variable to check if 
#the variances of mpg are equal or not on am variable categories

airquality$Month <- factor(airquality$Month)
bartlett_result <- bartlett.test(Temp ~ Month, data = airquality)
print(bartlett_result)

#c) 	Discuss which independent sample test must be used to compare “Temp” variable by “Month” 
#variable categories based on the results obtained above.

#Bartlett’s test in the above case suggests that the “Temp” variable’s variances
#are roughly equal between months. Consequently, the conventional 
#one-way ANOVA is appropriate.

#d) perform the best independent sample statistical test for this data now and interpret the result carefully.
data("airquality")
anova_model <- aov(Temp ~ Month, data = airquality)
summary(anova_model)
airquality$Month <- factor(airquality$Month)
anova_model <- aov(Temp ~ Month, data = airquality)
tukey_result <- TukeyHSD(anova_model)
print(tukey_result)
# Here we can see relationship between temp and month of (6-5),(7-5),(8-5),(9-5) are less significant
#as compared to month of (9-6),(8-7).
```
## QUESTION NO 9
```{r}



library(stats)
city_distances <- matrix(c(
  0, 587, 1212, 701, 1936, 604, 748, 2139, 2182, 543,
  587, 0, 920, 940, 1745, 1188, 713, 1858, 1737, 597,
  1212, 920, 0, 879, 831, 1726, 1611, 1949, 2204, 1494,
  701, 940, 879, 0, 1374, 968, 1420, 1645, 1891, 1220,
  1936, 1745, 831, 1374, 0, 2339, 2451, 347, 2734, 2300,
  604, 1188, 1726, 968, 2339, 0, 1092, 2594, 2408, 923,
  748, 713, 1611, 1420, 2451, 1092, 0, 2571, 678, 205,
  2139, 1858, 1949, 1645, 347, 2594, 2571, 0, 678, 2442,
  2182, 1737, 2204, 1891, 2734, 2408, 678, 678, 0, 2329,
  543, 597, 1494, 1220, 2300, 923, 205, 2442, 2329, 0
), nrow = 10, byrow = TRUE)

# Assigning names to row and columns
city_names <- c("Atlanta", "Chicago", "Denver", "Houston", "Los Angeles", "Miami",
                "New York", "San Francisco", "Seattle", "Washington D.C.")
rownames(city_distances) <- city_names
colnames(city_distances) <- city_names

## A)
## Get dissimilarity distance as city.dissimilarity object
city.dissimilarity <- as.dist(city_distances)

## B)
## Fit the classical MDS model using city.dissimilarity object
mds.model <- cmdscale(city.dissimilarity, eig = TRUE, k = 2)  # Dimension 2


## C)
# Summary of model
mds.points <- mds.model$points
print(mds.points)
## Interpretation
# These coordinates represent the cities' positions relative to each other based on their pairwise distances.


## D)
## Bi-plot of the model
plot(mds.points, type = "n")
text(mds.points, labels = city_names, cex = 0.7)

## Interpretation
# - The bi-plot visually represents the cities' positions in the 2D space.
#- The distances between cities in this plot reflect their dissimilarities from the original distance matrix.
#- Cities close together in the plot are more similar (based on the original distances), while those farther apart are more dissimilar.
#In summary, the code performs classical MDS on city distances, obtains 2D coordinates, and creates a bi-plot to visualize the cities' relative positions.
```

#QUESTION NO. 8
```{r}


library(car)
## Loading required package: carData
# Create "crime" dataset
crime_data <- Arrests
head(crime_data)

set.seed(10)
index <- sample(2, size = nrow(crime_data),replace = TRUE, prob = c(0.7, 0.3))
train_full <- crime_data[index ==1,]
test_full <- crime_data[index ==2,]
crime_data_full <- crime_data
```



```{r}
#QUESTION NO 6
library(ggplot2)
set.seed(10)

## A)
age <- sample(10:99, 200, replace = TRUE)
sex <- sample(c("Male", "Female"), 200, replace = TRUE)
education <- sample(c("No education", "Primary", "Secondary", "Beyond secondary"), 200, replace = TRUE)
socioeconomic_status <- sample(c("Low", "Middle", "High"), 200, replace = TRUE)
bmi <- sample(14:38, 200, replace = TRUE)

## B)
ggplot(data = data.frame(age, bmi), aes(x = age, y = bmi)) +
  geom_point() +
  labs(x = "Age", y = "BMI", title = "Relationship between Age and BMI")

##  the data is well spread as No trend is seen from the data.

## C)
bmi_class <- cut(bmi, breaks = c(0, 18, 24, 30, Inf), labels = c("<18", "18-24", "25-30", "30+"))

ggplot(data.frame(bmi_class), aes(x = "", fill = bmi_class)) +
  geom_bar(width = 1) +
  coord_polar("y", start = 0) +
  labs(title = "Distribution of BMI Classes") +
  theme_void() +
  theme(legend.position = "right")

##the maximum part of the data is covered by group 25-30 and 30+ 
#and minimum part of the data is from <18 

## D)

ggplot(data.frame(age), aes(x = age)) +
  geom_histogram(binwidth = 15, fill = "steelblue", color = "white") +
  labs(x = "Age", y = "Count", title = "Distribution of Age") +
  theme_classic()
#From above plot we can see thet all the data has simmilar frequency except highest one
```