library(car)
# setting random seed with my roll number to replicate the result
set.seed(22)
# creating a mpg variable according to question
mpg <- sample(c(10:50), size = 500, replace = TRUE)
# Plot histogram of mpg variable
hist(mpg)
hist(mpg, col = "blue", breaks = 8)
abline(v=mean(mpg), col = 'red')
qqnorm(mpg, main = "QQ Plot of mpg variable with normal QQ-line in red color")
qqline(mpg, col = 'red', lwd = 2)
dens <- density(mpg)
plot(dens, main = "Density plot of mpg")
polygon(dens, col = "yellow", border = NA)
'6 OR
----------
Define the first layer of the ggplot object with diamond data, carat as x-axis and price as y-axis
Add layer with geometric aesthetic as "point", statistics and position as "identity"
Add layers with scale of y and x variables as continuous
Add layer with coordinate system as Cartesian
Add layer with appropriate title and interpret the resulting graph carefully
'
library(ggplot2)
library(caret)
ggplot(data = diamonds, mapping = aes(x = carat, y = price)) +
geom_point(stat = 'identity', position = 'identity') +
scale_x_continuous() + scale_y_continuous() +
coord_cartesian() +
labs(title = "Relationship between carat and price")
# Layered version of code
ggplot(data = diamonds, mapping = aes(carat, price)) +
layer(geom = 'point', stat = 'identity', position = 'identity') +
scale_x_continuous() + scale_y_continuous() +
coord_cartesian()
# ALternative layer version code
ggplot() + layer(data = diamonds, mapping = aes(x = carat, y = price),
geom = "point", stat = "identity",
position = "identity") +
scale_x_continuous() + scale_y_continuous() +
coord_cartesian()
'7
-------------
Do the following in R Studio with R script so that it can be knitted as PDF:
Prepare a data with 100 random observations and two variables: miles per gallon (mpg) with random
range between 10 to 50 and transmission gears (gear) as random binary variable (3 = three gear, 4=four gear and 5-five gears), do not forget to use your class roll number as random seed to replicate the result)
Perform goodness-of-fit test on miles per gallon (mpg) variable to check if the variances are equal or not on gears variable categories
Perform the best 1-way analysis of variance test based on goodness-of-fit results with justification.
Can you use this test for this data? Interpret the result carefully, if applicable.
'
set.seed(22)
mpg <- sample(c(10:50), size = 100, replace = T)
gears <- as.factor(sample(c(3, 4, 5), size = 100, replace = T))
mpg_data <- data.frame(mpg = mpg, gears = gears)
head(mpg_data)
# Performance goodness-of-fit test on mpg to check if variances are equal or not on gears variable
levene_result <- leveneTest(mpg~gears, data = mpg_data)
levene_result
# Normality check for mpg variable across each categories
normality_check_category <- function(data)
{
result <- tapply(data$mpg, data$gears, shapiro.test)
return(result)
}
table(mpg_data$gears)
shapiro_test_results <- normality_check_category(data = mpg_data)
shapiro_test_results
test_result <- kruskal.test(mpg~gears, data = mpg_data)
print(test_result)
# Post Hoc Test
install.packages('dunn.test')
# Post Hoc Test
library(dunn.test)
# Perform Dunn's test
dunn_result <- dunn.test(mpg_data$mpg, mpg_data$gears,  method="bonferroni")
# Print the results
print(dunn_result)
'8
--------------
Do the followings in R Studio using R script so that it can be knitted as PDF:
b) Prepare a data with 200 random observations and four variables: miles per gallon (mpg) with random range between 10 to 50;
transmission (am) as random binary variable (0=automatic, 1=Manual), weight (wt) with random range of 1 to 10 and
horse power (hp) with random range of 125 and 400, do not forget
to use your exam roll number as random seed to replicate the result
c) Divide this data into train and test datasets with 70:30 random splits with your exam roll number as random seed for replication
d) Fit a supervised linear regression model for the train data
e) Explain the model fit and BLUE coefficients for the fitted model
f) Predict the mpg variable in the test data, get fit indices and interpret them carefully
'
set.seed(22)
df <- data.frame(mpg = sample(c(10:50), size = 200, replace = T),
am = as.factor(sample(c(0, 1), size = 200, replace = T)),
wt = sample(c(1:10), size = 200, replace = T),
hp = sample(c(125:400), size = 200, replace = T)
)
head(df)
set.seed(22)
index<- sample(2, size = nrow(df), replace = T, prob = c(0.7, 0.3))
train_df <- df[index == 1, ]
test_df <- df[index ==2, ]
print(nrow(train_df))
print(nrow(test_df))
# Fit a supervised linear regression with training data
linear_reg <- lm(formula = mpg ~ ., data = train_df)
# Checking vif scores to see if there is any multicollinearity present in the dataset
vif(linear_reg)
# Since vif score less than 10, we can say that the features are not correlated with each other to a higher degree.
print(summary(linear_reg))
normalize_func <- function(x) {
scaled_values <- ((x-min(x))/ (max(x) - min(x)))
return(scaled_values)
}
scaled_train_df <- train_df
scaled_train_df$wt <- normalize_func(scaled_train_df$wt)
scaled_train_df$hp <- normalize_func(scaled_train_df$hp)
scaled_test_df <- test_df
scaled_test_df$wt <- normalize_func(scaled_test_df$wt)
scaled_test_df$hp <- normalize_func(scaled_test_df$hp)
# Fit a supervised linear regression with training data
scaled_linear_reg <- lm(formula = mpg ~ ., data = scaled_train_df)
# Checking vif scores to see if there is any multicollinearity present in the dataset
vif(scaled_linear_reg)
# Since vif score less than 10, we can say that the features are not correlated with each other to a higher degree.
print(summary(scaled_linear_reg))
new_df <- df
new_df$am <- as.integer(df$am)
# Finding correlations
cor(new_df)
# Plot to see linear relationship exists between mpg and wt variable
plot(new_df$mpg, new_df$wt)
# Intercept only model
intercept_only_model <- lm(mpg ~ 1, data = scaled_train_df)
full_model <- lm(mpg~., data = scaled_train_df)
# Perform an F-test to compare the models
anova(intercept_only_model, full_model)
# From this we can see that the p value is greater tha n 0.05 which concludes that predictors in the full model does not
# provide a better fit than the intercept only model.
library(car)
density <- density(train_df$mpg)
plot(density)
polygon(density, col = 'red')
# Fit the model on the test dataset and get the indices and interpret them
predictions <- predict(scaled_linear_reg, scaled_test_df)
library(caret)
indices <- data.frame(
R2 = R2(predictions, scaled_test_df$mpg),
RMSE = RMSE(predictions, scaled_test_df$mpg),
MAE = MAE(predictions, scaled_test_df$mpg)
)
"9
-----------
Do the following in R Studio with R script so that it can be knitted as PDF:
a) Prepare a data with four random variables and 300 observations: miles per gallon (mpg) with random
range between 10 to 50; transmission (am) as random binary variable (0-automatic, I-Manual), weight
(wt) with random range of 1 to 10 and horse power (hp) with random range of 125 and 400, do not forget
to use your exam roll number as random seed to replicate the result
b) Divide this data into train and test datasets with 80:20 random splits with your exam roll number as
random seed for replication
c) Fit a supervised logistic regression model on train data with transmission (am) as dependent variable and
miles per gallon (mpg), horse power (hp) and weight (wt) as independent variable
d) Predict the transmission variable in the test data and interpret the predicted result carefully
e) Get the confusion matrix, sensitivity, specificity of the predicted model and interpret them carefully
"
indices
